 \documentclass[12pt]{article}
 \headsep 0.4 true cm
 \pagestyle{plain}
 \topmargin 5pt
 \oddsidemargin 16pt
 \textheight 22.5 true cm
 \textwidth 15.5 true cm
 \parskip 0.08cm
 \renewcommand\baselinestretch{1.6}
 \parindent=20pt
 %\nofiles
 \def\hang{\hangindent\parindent}
 \def\re{\par\hang\noindent}
 \def\be{\begin{equation}}
 \def\ee{\end{equation}}
 \def\beqn{\begin{eqnarray}}
 \def\eeqn{\end{eqnarray}}
 \def\beqn*{\begin{eqnarray*}}
 \def\eeqn*{\end{eqnarray*}}

 \usepackage{graphicx}


 \title{Covariance of Sample Mean and Sample Standard Deviation}

 \vskip 0.3cm
 \author{Lingyun Zhang\thanks{Stats New Zealand,
 8 Willis Street,
 PO Box 2922,
 Wellington 6011,
 New Zealand, Email: lyzhang10@gmail.com}}
 \vskip 0.3cm

 \begin{document}

 %\date{}
 \maketitle


 \begin{abstract}
Without the assumption of normality we derive the first order
asymptotic covariance of the sample mean and sample standard
deviation in a rather elementary way.

\noindent {\bf KEY WORDS}: Third central moment; asymptotic
covariance; asymptotic correlation.

%\noindent 2000 Mathematics Subject Classification: 62-01
\end{abstract}

 \section{Introduction}

 Let $\{X_1, X_2, \ldots, X_n\}$ be a random sample (i.e. $X_1, X_2, \ldots, X_n$ are independent and
 identically distributed). The sample
 mean and sample standard deviation are defined respectively as:
 $$
 \bar{X}=\frac{1}{n}\sum_{i=1}^n X_i, \quad
 S=\sqrt{S^2}=\sqrt{\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2}.
 $$
If the sample is taken from a normal
population, then $\bar{X}$ and $S^2$ are independent.
Without the assumption of normality, Zhang (2007)
shows that the covariance of
$\bar{X}$ and $S^2$ is $\mu_3/n$, where $\mu_3$ is the third
central moment of $X_1$ and $n$ denotes the sample size, and Sen (2012) provides the correlation between $\bar{X}$ and $S^2$.
%Zhang's paper has been cited by, On Student's 1908 Article ``The Probable
%Error of a Mean", publish in the {\it Journal of the American
%Statistical Association} (Zabell, 2008).
Now naturally it is of interest to
know what the covariance of $\bar{X}$ and $S$ is without the
assumption of normality. In the next section we present our main
results; we give the proofs in Section~3 and an example in Section~4.


 \section{Main Results}

In what follows, denote the mean, variance, third and fourth
central moments of $X_1$ by $\mu$, $\sigma^2$,  $\mu_3$ and
$\mu_4$, respectively.

\noindent {\bf Theorem 1.} {\it The asymptotic covariance of
$\bar{X}$ and $S$ is}
\be
\frac{\mu_3}{2n\sigma}.
\label{cov}
\ee


%\noindent {\bf Theorem 2.} {\it The variance of $S$ is}

\noindent {\bf Corollary.} {\it The asymptotic correlation between
$\bar{X}$ and $S$ is} \be \frac{\gamma_1}{\sqrt{\gamma_2+2}},
\label{corr} \ee where
$$
\gamma_1=\frac{\mu_3}{\sigma^3}, \ \hbox{and}\
\gamma_2=\frac{\mu_4}{\sigma^4}-3.
$$
\noindent {\bf Remark 1}: In Miller (1997), p. 7, the result of
(\ref{corr}) has been given, but there is no proof or derivation.
In the next section, we show how
to obtain (\ref{corr}).


\section{Proofs}

{\it Proof of Theorem 1.} Let
$$
Y_i=\frac{X_i-\mu}{\sigma}, \quad \hbox{for}\ i=1, 2, \ldots, n.
$$
It follows that
$$
\bar{X}=\sigma \bar{Y} + \mu, \ \hbox{and}\ S=\sigma S_Y,
$$
where $\bar{Y}$ and $S_Y$ are the sample mean and sample standard deviation of
$\{Y_1, Y2, \ldots, Y_n\}$. Thus,
\begin{eqnarray*}
 \hbox{cov}(\bar{X}, S)
&=&\hbox{cov}(\sigma\bar{Y}+\mu, \sigma S_Y)\\
&=&\sigma^2 \hbox{cov}(\bar{Y}, S_Y)\\
&=&\sigma^2 E\left(\bar{Y}S_Y\right).
\end{eqnarray*}
Since the Taylor's expansion of function $f(x)=\sqrt{x}$ at $x=1$
is
$$
1+\frac{1}{2}(x-1)+o(x-1),
$$
we have
$$
S_Y\approx 1+\frac{1}{2}(S_Y^2-1)=\frac{1}{2}(S_Y^2+1),
$$
from which it follows that
\begin{eqnarray*}
E(\bar{Y}S_Y)&\approx
 & \frac{1}{2}E\left(\bar{Y}(S_Y^2+1)\right)\\
&=&\frac{1}{2}E(\bar{Y}S_Y^2)\\
&=&\frac{1}{2}\frac{E(Y_1^3)}{n}\ \ \hbox{(according to Zhang,
2007)}\\
&=&\frac{1}{2}\frac{\mu_3}{\sigma^3 n}.
\end{eqnarray*}
Therefore,
$$
\hbox{cov}(\bar{X}, S)\approx \sigma^2 \frac{1}{2}\frac{\mu_3}{\sigma^3
n}=\frac{\mu_3}{2n\sigma}.
$$

\vspace{0.5cm}
\noindent
 {\it Proof of the Corollary.} We have obtained the asymptotic covariance of $\bar{X}$ and $S$, and we need to derive
the variances of $\bar{X}$ and $S$.
 Since
 $$
 \hbox{Var}(\bar{X})=\frac{\sigma^2}{n}, \ \hbox{and}\
 \hbox{Var}(S)=E(S^2)-(E(S))^2=\sigma^2-(E(S))^2,
 $$
 we only need to show how to derive
 the asymptotic mean of $S$. If we keep the quadratic term, then the
 Taylor's expansion of $\sqrt{x}$ at $x=1$ is
 $$
 \sqrt{x}=1+\frac{1}{2}(x-1)-\frac{1}{8}(x-1)^2+o((x-1)^2).
 $$
 Now we have
 $$
 S_Y\approx 1+\frac{1}{2}(S_Y^2-1)-\frac{1}{8}(S_Y^2-1)^2.
 $$
 Thus,
 \begin{eqnarray*}
  E(S)&=&E(\sigma S_Y)\\
      &\approx& \sigma \left[1-\frac{1}{8}\hbox{Var}(S_Y^2)\right]\\
      &=& \sigma\left[1-\frac{1}{8}\left(\frac{2}{n-1}+\frac{EY_1^4-3}{n}\right)\right]\\
      &=&\sigma\left[1-\frac{1}{8}\left(\frac{2}{n-1}+\frac{\gamma_2}{n}\right)
      \right];
 \end{eqnarray*}
it follows that
$$
 \hbox{Var}(S)\approx
 \frac{\sigma^2}{4}\left(\frac{2}{n-1}+\frac{\gamma_2}{n}\right),
$$
if the $o(\frac{1}{n})$ terms are discarded. (Note that in the
above for the variance of $S_Y^2$, we used
the formula in Miller, 1997, p. 7. A direct derivation of the variance formula is available from the author upon request.)

\section{An Example}

The accuracy of (\ref{cov}) depends on the parent distribution and sample size $n$. In this section, we use an example to illustrate the accuracy of (\ref{cov}).

Let $X_1, X_2, \ldots, X_n$ be independent and identically distributed Bernoulli random variables and $P(X_1=1)=p$, where $0<p<1$. In this case the third central moment of $X_1$
$$
\mu_3=p(1-p)(1-2p),
$$
and the standard deviation of $X_1$
$$
\sigma=\sqrt{p(1-p)},
$$
thus the asymptotic covariance of $\bar{X}$ and $S$ is
\be
\frac{\mu_3}{2n\sigma}=\frac{\sqrt{p(1-p)}(1-2p)}{2n}.\label{AsyCovBernou}
\ee

%Insert Table 1 here
\begin{table}[htbp]
\begin{center}
\caption{For various values of $n$ and $p$, the covariances obtained by using (\ref{covBernou}) (indicated by ``Exact") and (\ref{AsyCovBernou}).}
\begin{tabular}{c|ccccc}
\hline
\hline
    & $n=5$ & $n=10$ & $n=20$ & $n=30$ & $n=50$\\
    \hline
    & \multicolumn{5}{|c}{$p=0.1$}\\
Exact & 0.0290& 0.0158& 0.0074& 0.0046& 0.0025\\
(3)   & 0.0240& 0.0120& 0.0060& 0.0040& 0.0024\\
\hline
    & \multicolumn{5}{|c}{$p=0.25$}\\
Exact & 0.0333& 0.0139& 0.0059& 0.0038& 0.0022\\
(3)   & 0.0217& 0.0108& 0.0054& 0.0036& 0.0022\\
\hline
    & \multicolumn{5}{|c}{$p=0.75$}\\
Exact & -0.0333& -0.0139& -0.0059& -0.0038& -0.0022\\
(3)   & -0.0217& -0.0108& -0.0054& -0.0036& -0.0022\\
\hline
    & \multicolumn{5}{|c}{$p=0.9$}\\
Exact & -0.0290& -0.0158& -0.0074& -0.0046& -0.0025\\
(3)   & -0.0240& -0.0120& -0.0060& -0.0040& -0.0024\\
\hline
\end{tabular}
\end{center}
\end{table}

\noindent
Noticing that $X_i^2=X_i$ for $i=1, 2, \ldots, n$, we have
\begin{eqnarray}
S^2&=&\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2 \nonumber \\
   &=&\frac{1}{n-1}\left[\sum_{i=1}^nX_i-\frac{1}{n}\left(\sum_{i=1}^nX_i\right)^2\right] \nonumber \\
   &\equiv& \frac{1}{n-1}\left(T_n - \frac{1}{n}T_n^2\right), \label{S2}
\end{eqnarray}
where $T_n=\sum_{i=1}^nX_i$ and it has the binomial distribution $b(n, p)$. Using (\ref{S2}), we write
\begin{eqnarray}
\hbox{cov}(\bar{X}, S)&=&\hbox{cov}\left(\displaystyle\frac{1}{n}T_n, \frac{1}{\sqrt{n-1}}\sqrt{T_n-\frac{1}{n}T_n^2}\right)\nonumber\\
&=&\displaystyle\frac{1}{n\sqrt{n-1}}\left[E\left(T_n\sqrt{T_n-\frac{1}{n}T_n^2}\right)-E\left(T_n\right)E\left(\sqrt{T_n-\frac{1}{n}T_n^2}\right)\right]\nonumber\\
&=&\displaystyle\frac{1}{n\sqrt{n-1}}\left[\sum_{j=1}^n j\sqrt{j-\frac{1}{n}j^2}p_j-np\sum_{j=1}^n \sqrt{j-\frac{1}{n}j^2}p_j\right],\label{covBernou}
\end{eqnarray}
where the binomial probability mass
$$
p_j=\left(
\begin{array}{c}
n\\
j
\end{array}
\right)p^j(1-p)^{n-j}, \ \hbox{for}\ j=1, 2, \ldots, n.
$$
For some given values of $n$ and $p$, we use (\ref{covBernou}) and (\ref{AsyCovBernou}) to compute the exact and asymptotic covariance respectively; we present the results in Table~1. We see from Table~1 that (\ref{AsyCovBernou}) is accurate even for the sample size $n$ as small as $5$.

\noindent
{\bf Remark 2}: For $p=0.5$ regardless of the value of $n$, our numerical results suggest that the covariance is equal to $0$.




\section*{Acknowledgements} I thank Dr. Kit Withers for useful discussion.

\section*{Reference}

\re{} Miller, R. G. (1997). {\it Beyond ANOVA}. Chapman and
Hall.

\re{} Sen, A. (2012). On the Interrelation Between the Sample Mean and the
Sample Variance. {\it The American
Statistician}, {\bf 66}, 112-117.


\re{} Zhang, L. (2007). Sample Mean and Sample Variance: Their
Covariance and Their (In)Dependence. {\it The American
Statistician}, {\bf 61}, 159-160.


 \end{document}
